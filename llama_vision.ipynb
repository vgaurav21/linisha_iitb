{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1683488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ollama\n",
    "import ollama\n",
    "import cv2\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42306752",
   "metadata": {},
   "source": [
    "### Bunch of hats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ac3b7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# response 1\n",
    "# Step 1: Ask Llama 3.2 Vision to locate the object\n",
    "response1 = ollama.chat(\n",
    "    model=\"llama3.2-vision\",\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Locate the red hat in this image and return only its bounding box in JSON format of {x: , y: , width: , height: } with un-normalised pixel values.\",\n",
    "        \"images\": [\"red_hat.jpg\"]  # Replace with your actual image path\n",
    "    }]\n",
    ")\n",
    "\n",
    "print(response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c7f750",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#response 1\n",
    "try:\n",
    "    bbox_json_start = response1[\"message\"][\"content\"].find(\"{\")\n",
    "    bbox_json_end = response1[\"message\"][\"content\"].rfind(\"}\") + 1\n",
    "    bbox_string = response1[\"message\"][\"content\"][bbox_json_start:bbox_json_end]\n",
    "    bbox = json.loads(bbox_string)  # Convert string to JSON\n",
    "except (json.JSONDecodeError, ValueError) as e:\n",
    "    print(\"Error parsing JSON:\", e)\n",
    "    bbox = None  # Handle error gracefully\n",
    "\n",
    "# Step 3: Function to draw bounding box and display it in Jupyter Notebook\n",
    "def draw_and_display_bounding_box(image_path, coordinates, output_path=\"output1.jpg\"):\n",
    "    if not coordinates:\n",
    "        print(\"No bounding box detected. Exiting...\")\n",
    "        return\n",
    "\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for matplotlib\n",
    "\n",
    "    # Extract coordinates\n",
    "    x, y, w, h = coordinates[\"x\"], coordinates[\"y\"], coordinates[\"width\"], coordinates[\"height\"]\n",
    "\n",
    "#     # Draw bounding box (Green color, thickness = 2)\n",
    "#     height, width, _ = image.shape\n",
    "\n",
    "#     # Convert normalized bbox to pixel values\n",
    "#     x = int(coordinates[\"x\"] * width)\n",
    "#     y = int(coordinates[\"y\"] * height)\n",
    "#     w = int(coordinates[\"width\"] * width)\n",
    "#     h = int(coordinates[\"height\"] * height)\n",
    "    \n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Save the output image\n",
    "    cv2.imwrite(output_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "    print(f\"Image saved as {output_path}\")\n",
    "\n",
    "    # Display image in Jupyter Notebook\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")  # Hide axis for better visualization\n",
    "    plt.show()\n",
    "\n",
    "# Step 4: Call function to process the image\n",
    "draw_and_display_bounding_box(\"red_hat.jpg\", bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e74d26",
   "metadata": {},
   "source": [
    "### Single red hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740409ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#response 2\n",
    "# Step 1: Ask Llama 3.2 Vision to locate the object\n",
    "response2 = ollama.chat(\n",
    "    model=\"llama3.2-vision\",\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Locate the red hat in this image and return only its bounding box in JSON format of {x: , y: , width: , height: } with un-normalised pixel values..\",\n",
    "        \"images\": [\"only_red.jpg\"]  # Replace with your actual image path\n",
    "    }]\n",
    ")\n",
    "\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5be3e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#response 2\n",
    "try:\n",
    "    bbox_json_start = response2[\"message\"][\"content\"].find(\"{\")\n",
    "    bbox_json_end = response2[\"message\"][\"content\"].rfind(\"}\") + 1\n",
    "    bbox_string = response2[\"message\"][\"content\"][bbox_json_start:bbox_json_end]\n",
    "    bbox = json.loads(bbox_string)  # Convert string to JSON\n",
    "except (json.JSONDecodeError, ValueError) as e:\n",
    "    print(\"Error parsing JSON:\", e)\n",
    "    bbox = None  # Handle error gracefully\n",
    "\n",
    "# Step 3: Function to draw bounding box and display it in Jupyter Notebook\n",
    "def draw_and_display_bounding_box(image_path, coordinates, output_path=\"output2.jpg\"):\n",
    "    if not coordinates:\n",
    "        print(\"No bounding box detected. Exiting...\")\n",
    "        return\n",
    "\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for matplotlib\n",
    "\n",
    "    # Extract coordinates\n",
    "    x, y, w, h = coordinates[\"x\"], coordinates[\"y\"], coordinates[\"width\"], coordinates[\"height\"]\n",
    "\n",
    "    # Draw bounding box (Green color, thickness = 2)\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Save the output image\n",
    "    cv2.imwrite(output_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "    print(f\"Image saved as {output_path}\")\n",
    "\n",
    "    # Display image in Jupyter Notebook\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")  # Hide axis for better visualization\n",
    "    plt.show()\n",
    "\n",
    "# Step 4: Call function to process the image\n",
    "draw_and_display_bounding_box(\"only_red.jpg\", bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f97b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install required libraries if not already installed\n",
    "# # !pip install ollama opencv-python matplotlib\n",
    "\n",
    "# # Step 2: Extract bounding box coordinates from Llama's response\n",
    "# bbox = json.loads(response2[\"message\"][\"content\"])\n",
    "\n",
    "# # Step 3: Function to draw and display bounding box in Jupyter Notebook\n",
    "# def draw_and_display_bounding_box(image_path, coordinates, output_path=\"output.jpg\"):\n",
    "#     # Load the image\n",
    "#     image = cv2.imread(image_path)\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for matplotlib\n",
    "\n",
    "#     # Extract coordinates\n",
    "#     x, y, w, h = coordinates[\"x\"], coordinates[\"y\"], coordinates[\"width\"], coordinates[\"height\"]\n",
    "\n",
    "#     # Draw bounding box (Green color, thickness = 2)\n",
    "#     cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "#     # Save the output image\n",
    "#     cv2.imwrite(output_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "#     print(f\"Image saved as {output_path}\")\n",
    "\n",
    "#     # Display image in Jupyter Notebook\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     plt.imshow(image)\n",
    "#     plt.axis(\"off\")  # Hide axis for better visualization\n",
    "#     plt.show()\n",
    "\n",
    "# # Step 4: Call function to process the image\n",
    "# draw_and_display_bounding_box(\"only_red.jpg\", bbox)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cc9957",
   "metadata": {},
   "source": [
    "### Satellite image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9a33f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ollama\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='llama3.2-vision',\n",
    "    messages=[{\n",
    "        'role': 'user',\n",
    "        'content': 'What is in this image?',\n",
    "        'images': ['image.jpg']\n",
    "    }]\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc0b531",
   "metadata": {},
   "source": [
    "### Blue t-shirt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4187a834",
   "metadata": {},
   "outputs": [],
   "source": [
    "response3 = ollama.chat(\n",
    "    model=\"llama3.2-vision\",\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Locate the person wearing blue t-shirt in this image and return only its bounding box in JSON format of {x: , y: , width: , height: } with un-normalised pixel values..\",\n",
    "        \"images\": [\"blue_shirt.jpg\"]  # Replace with your actual image path\n",
    "    }]\n",
    ")\n",
    "\n",
    "print(response3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360d255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    bbox_json_start = response3[\"message\"][\"content\"].find(\"{\")\n",
    "    bbox_json_end = response3[\"message\"][\"content\"].rfind(\"}\") + 1\n",
    "    bbox_string = response3[\"message\"][\"content\"][bbox_json_start:bbox_json_end]\n",
    "    bbox = json.loads(bbox_string)  # Convert to JSON\n",
    "except (json.JSONDecodeError, ValueError) as e:\n",
    "    print(\"Error parsing JSON:\", e)\n",
    "    bbox = None  # Handle error gracefully\n",
    "\n",
    "# Step 3: Function to draw bounding box and display image\n",
    "def draw_and_display_bounding_box(image_path, coordinates, output_path=\"output3.jpg\"):\n",
    "    if not coordinates:\n",
    "        print(\"No bounding box detected. Exiting...\")\n",
    "        return\n",
    "\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "\n",
    "    # Extract coordinates\n",
    "    x, y, w, h = coordinates[\"x\"], coordinates[\"y\"], coordinates[\"width\"], coordinates[\"height\"]\n",
    "\n",
    "    # Draw bounding box (Fixed: Ensure the box is closed)\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Save the output image\n",
    "    cv2.imwrite(output_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "    print(f\"Image saved as {output_path}\")\n",
    "\n",
    "    # Display image in Jupyter Notebook\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")  # Hide axis for better visualization\n",
    "    plt.show()\n",
    "\n",
    "# Step 4: Run function\n",
    "draw_and_display_bounding_box(\"blue_shirt.jpg\", bbox)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b77ce1",
   "metadata": {},
   "source": [
    "### Paddington"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdd6698",
   "metadata": {},
   "outputs": [],
   "source": [
    "response4 = ollama.chat(\n",
    "    model=\"llama3.2-vision\",\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Locate the hat in this image and return only its bounding box in JSON format of {x: , y: , width: , height: } without normalising pixel values..\",\n",
    "        \"images\": [\"paddington.jpg\"]  # Replace with your actual image path\n",
    "    }]\n",
    ")\n",
    "\n",
    "print(response4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a287322",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    bbox_json_start = response4[\"message\"][\"content\"].find(\"{\")\n",
    "    bbox_json_end = response4[\"message\"][\"content\"].rfind(\"}\") + 1\n",
    "    bbox_string = response4[\"message\"][\"content\"][bbox_json_start:bbox_json_end]\n",
    "    bbox = json.loads(bbox_string)  # Convert to JSON\n",
    "except (json.JSONDecodeError, ValueError) as e:\n",
    "    print(\"Error parsing JSON:\", e)\n",
    "    bbox = None  # Handle error gracefully\n",
    "\n",
    "# Step 3: Function to draw bounding box and display image\n",
    "def draw_and_display_bounding_box(image_path, coordinates, output_path=\"output4.jpg\"):\n",
    "    if not coordinates:\n",
    "        print(\"No bounding box detected. Exiting...\")\n",
    "        return\n",
    "\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "\n",
    "    # Extract coordinates\n",
    "    x, y, w, h = coordinates[\"x\"], coordinates[\"y\"], coordinates[\"width\"], coordinates[\"height\"]\n",
    "\n",
    "        # Draw bounding box (Green color, thickness = 2)\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    # Convert normalized bbox to pixel values\n",
    "    x = int(coordinates[\"x\"] * width)\n",
    "    y = int(coordinates[\"y\"] * height)\n",
    "    w = int(coordinates[\"width\"] * width)\n",
    "    h = int(coordinates[\"height\"] * height)\n",
    "    # Draw bounding box (Fixed: Ensure the box is closed)\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Save the output image\n",
    "    cv2.imwrite(output_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "    print(f\"Image saved as {output_path}\")\n",
    "\n",
    "    # Display image in Jupyter Notebook\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")  # Hide axis for better visualization\n",
    "    plt.show()\n",
    "\n",
    "# Step 4: Run function\n",
    "draw_and_display_bounding_box(\"paddington.jpg\", bbox)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79850c2",
   "metadata": {},
   "source": [
    "### 04-03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7139c06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response5 = ollama.chat(\n",
    "    model=\"llama3.2-vision\",\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "#         \"content\": \"Is there a human in the image, if so, return its bounding box in JSON format of {x: , y: , width: , height: } with un-normalised pixel values..\",\n",
    "        \"content\": \"How many people are there in the image1/\",\n",
    "        \"images\": [\"123.jpg\"]  # Replace with your actual image path\n",
    "    }]\n",
    ")\n",
    "\n",
    "print(response5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8b3d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    bbox_json_start = response5[\"message\"][\"content\"].find(\"{\")\n",
    "    bbox_json_end = response5[\"message\"][\"content\"].rfind(\"}\") + 1\n",
    "    bbox_string = response5[\"message\"][\"content\"][bbox_json_start:bbox_json_end]\n",
    "    bbox = json.loads(bbox_string)  # Convert to JSON\n",
    "except (json.JSONDecodeError, ValueError) as e:\n",
    "    print(\"Error parsing JSON:\", e)\n",
    "    bbox = None  # Handle error gracefully\n",
    "\n",
    "# Step 3: Function to draw bounding box and display image\n",
    "def draw_and_display_bounding_box(image_path, coordinates, output_path=\"output5.jpg\"):\n",
    "    if not coordinates:\n",
    "        print(\"No bounding box detected. Exiting...\")\n",
    "        return\n",
    "\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "\n",
    "        # Draw bounding box (Green color, thickness = 2)\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    # Convert normalized bbox to pixel values\n",
    "    x = int(coordinates[\"x\"] * width)\n",
    "    y = int(coordinates[\"y\"] * height)\n",
    "    w = int(coordinates[\"width\"] * width)\n",
    "    h = int(coordinates[\"height\"] * height)\n",
    "    # Extract coordinates\n",
    "    x, y, w, h = coordinates[\"x\"], coordinates[\"y\"], coordinates[\"width\"], coordinates[\"height\"]\n",
    "\n",
    "        # Draw bounding box (Green color, thickness = 2)\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    # Convert normalized bbox to pixel values\n",
    "    x = int(coordinates[\"x\"] * width)\n",
    "    y = int(coordinates[\"y\"] * height)\n",
    "    w = int(coordinates[\"width\"] * width)\n",
    "    h = int(coordinates[\"height\"] * height)\n",
    "    # Draw bounding box (Fixed: Ensure the box is closed)\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Save the output image\n",
    "    cv2.imwrite(output_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "    print(f\"Image saved as {output_path}\")\n",
    "\n",
    "    # Display image in Jupyter Notebook\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")  # Hide axis for better visualization\n",
    "    plt.show()\n",
    "\n",
    "# Step 4: Run function\n",
    "draw_and_display_bounding_box(\"123.jpg\", bbox)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dbd999",
   "metadata": {},
   "source": [
    "### soldier image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff03f603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model='llama3.2-vision' created_at='2025-03-04T11:27:54.9647849Z' done=True done_reason='stop' total_duration=340788885800 load_duration=311641700 prompt_eval_count=15 prompt_eval_duration=276181000000 eval_count=150 eval_duration=63833000000 message=Message(role='assistant', content=\"The image depicts a person dressed in camouflage attire, holding a rifle and crouching in a wooded area.\\n\\nThe individual is attired in a camouflage jacket, hat, and sunglasses. They are grasping a silver-colored rifle with both hands, which is pointed to their right side. The rifle features a long barrel and a stock that extends from the butt of the gun to its rear end.\\n\\nThe person is situated within a wooded area, surrounded by trees and bushes. The foliage appears to be dense, as only a small portion of the individual's upper body is visible above the surrounding vegetation. The image conveys an atmosphere of stealth and caution, suggesting that the person may be on a hunting trip or engaged in some form of military training.\", images=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "response6 = ollama.chat(\n",
    "    model=\"llama3.2-vision\",\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "#         \"content\": \"Is there a human in the image, if so, return its bounding box in JSON format of {x: , y: , width: , height: } with un-normalised pixel values..\",\n",
    "        \"content\": \"Describe the image\",\n",
    "        \"images\": [\"soldier1.jpg\"]  # Replace with your actual image path\n",
    "    }]\n",
    ")\n",
    "\n",
    "print(response6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b9f071",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    bbox_json_start = response6[\"message\"][\"content\"].find(\"{\")\n",
    "    bbox_json_end = response6[\"message\"][\"content\"].rfind(\"}\") + 1\n",
    "    bbox_string = response6[\"message\"][\"content\"][bbox_json_start:bbox_json_end]\n",
    "    bbox = json.loads(bbox_string)  # Convert to JSON\n",
    "except (json.JSONDecodeError, ValueError) as e:\n",
    "    print(\"Error parsing JSON:\", e)\n",
    "    bbox = None  # Handle error gracefully\n",
    "\n",
    "# Step 3: Function to draw bounding box and display image\n",
    "def draw_and_display_bounding_box(image_path, coordinates, output_path=\"output6.jpg\"):\n",
    "    if not coordinates:\n",
    "        print(\"No bounding box detected. Exiting...\")\n",
    "        return\n",
    "\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "\n",
    "        # Draw bounding box (Green color, thickness = 2)\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    # Convert normalized bbox to pixel values\n",
    "    x = int(coordinates[\"x\"] * width)\n",
    "    y = int(coordinates[\"y\"] * height)\n",
    "    w = int(coordinates[\"width\"] * width)\n",
    "    h = int(coordinates[\"height\"] * height)\n",
    "    # Extract coordinates\n",
    "    x, y, w, h = coordinates[\"x\"], coordinates[\"y\"], coordinates[\"width\"], coordinates[\"height\"]\n",
    "\n",
    "        # Draw bounding box (Green color, thickness = 2)\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    # Convert normalized bbox to pixel values\n",
    "    x = int(coordinates[\"x\"] * width)\n",
    "    y = int(coordinates[\"y\"] * height)\n",
    "    w = int(coordinates[\"width\"] * width)\n",
    "    h = int(coordinates[\"height\"] * height)\n",
    "    # Draw bounding box (Fixed: Ensure the box is closed)\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Save the output image\n",
    "    cv2.imwrite(output_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "    print(f\"Image saved as {output_path}\")\n",
    "\n",
    "    # Display image in Jupyter Notebook\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")  # Hide axis for better visualization\n",
    "    plt.show()\n",
    "\n",
    "# Step 4: Run function\n",
    "draw_and_display_bounding_box(\"soldier1.jpg\", bbox)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
